# See https://www.robotstxt.org/robotstxt.html for documentation on how to use the robots.txt file
#
# This file is used to tell search engine crawlers which pages or files they can or cannot request from your site.

User-agent: *
Allow: /

Sitemap: https://staxmap.com/sitemap.xml
